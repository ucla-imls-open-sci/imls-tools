{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load API Key and OPENAI Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads all of the packages that will be used and the OpenAI API Key that will be used. Store your OpenAI API Key in a .env file.\n",
    "If you are missing any of these packages run the following commands\n",
    "```\n",
    "$   pip3 install PyPDF2\n",
    "$   pip3 install python.dotenv\n",
    "$   pip3 install openai\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import PyPDF2\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.organization = os.getenv(\"ORGANIZATION_KEY\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample API Call\n",
    "# response = openai.Completion.create(\n",
    "#     engine=\"text-davinci-002\",  # Specify the engine (model) you want to use\n",
    "#     prompt=\"Translate the following English text to French: 'Hello, how are you?'\",\n",
    "#     max_tokens=50,  # Limit the length of the generated text\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Lesson Proposals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson Proposals will be extracted using the PyPDF2 Package. You must have the lessons downloaded locally for this code to work and place it inside of a \n",
    "Lesson_Proposal folder. It will extract all of the text and put it into the <i style=\"color: red\"><b>proposal_text</b></i> variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stores the path of All the PDFs in the Lesson_Proposals Folder\n",
    "pdf_file_paths = []\n",
    "\n",
    "proposal_list = os.listdir(\"./Lesson_Proposals/\")\n",
    "\n",
    "# Extracts all the PDF Paths\n",
    "for i in proposal_list:\n",
    "    pdf_file_paths.append(f\"Lesson_Proposals/{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT TEXT FROM EACH PROPOSAL\n",
    "\n",
    "lesson_proposal = []\n",
    "\n",
    "for i in pdf_file_paths:\n",
    "    pdf_file = open(i, 'rb')\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "\n",
    "    text = ''\n",
    "    for page_num in range(len(pdf_reader.pages)):\n",
    "        page = pdf_reader.pages[page_num]\n",
    "        text += page.extract_text()\n",
    "    \n",
    "    pdf_file.close()\n",
    "    lesson_proposal.append(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting GPT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI's API currently doesn't support a continuous chat as far as im concerned. There are a lot of repositories that address this problem but I think the solution I will be going with is a long continuous chain, starting with providing a rubric to score similiarities, providing an output format, then ultimately providing all of the proposals. We can test this with the online version GPT prior to using the API to see if it generates the result we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening a Chat Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Chat:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Providing a Rubric\n",
    "\n",
    "You can find the Rubric that was used to score similarity [here](https://docs.google.com/document/d/1x18mVubT2H4Gj_GvDM3nUupCqYQHaH8Qk8UleAQjPyU/edit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Telling GPT to use this Rubric when Grading the Proposals\n",
    "\n",
    "rubric_message = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Telling GPT How to Output the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_message = \"\"\"\n",
    "Please respond in the following format: \n",
    "\n",
    "1. Proposal 1 Title\n",
    "    Most Similar: (Proposal Most Similar to)\n",
    "        3-5 Sentences of Context comparing the 2 proposals\n",
    "        Rubric Score:\n",
    "            ...\n",
    "    Least Similar: (Proposal Least Similar to)\n",
    "        3-5 Sentences of Content comparing the 2 proposals\n",
    "        Rubric Score:\n",
    "            ...\n",
    "2. Proposal 2 Title\n",
    "    Same format as above\n",
    "3. The same format until all proposals have been considered\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining all of the messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take all of the different messages created above and combine them together into one singular prompt that we can send to GPT.\n",
    "It will HOPEFULLY output an appropriate response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are going to receive several lesson proposals and your job is to compare them to find proposals that are most similar to each other. \n",
    "You will have a total of 7 proposals, A, B, C, etc. You will compare the proposals and see which is the most similar and least similar to each individual \n",
    "proposal. Each proposal will go through an individual comparison against each other. You will use the rubric that will be provided as a way to score\n",
    "the similarities between each proposal. This score will be used in your response.\n",
    "\n",
    "The Rubric:\n",
    "{rubric_message}\n",
    "\n",
    "{format_message}\n",
    "\n",
    "Here are the following proposals\n",
    "\n",
    "Proposal 1:\n",
    "{lesson_proposal[0]}\n",
    "\n",
    "Proposal 2:\n",
    "{lesson_proposal[1]}\n",
    "\n",
    "Proposal 3:\n",
    "{lesson_proposal[2]}\n",
    "\n",
    "Proposal 4:\n",
    "{lesson_proposal[3]}\n",
    "\n",
    "Proposal 5:\n",
    "{lesson_proposal[4]}\n",
    "\n",
    "Proposal 6:\n",
    "{lesson_proposal[5]}\n",
    "\n",
    "Proposal 7:\n",
    "{lesson_proposal[6]}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending the Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using OPENAI's API to prompt gpt-4 to analyze the text\n",
    "response = openai.Completion.create(\n",
    "    engine=\"gpt-4\",  # Specify the engine (model) you want to use\n",
    "    prompt=\"Translate the following English text to French: 'Hello, how are you?'\",\n",
    "    max_tokens=5000,  # Limit the length of the generated text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will create a new file/overwrite the \"GPT_Analysis.txt\" with GPT's text analysis of the lesson proposals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(response['choices'][0]['text'])\n",
    "GPT_Analysis = open(\"GPT_Analysis.txt\", 'w')\n",
    "GPT_Analysis.write(response['choices'][0]['text'])\n",
    "GPT_Analysis.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
